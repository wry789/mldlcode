{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(\"E:\\\\gitrep\\\\mygithub\\\\mldlcode\\\\HMM\\\\model\")\n",
    "from itertools import product\n",
    "from hmmlearn import hmm\n",
    "# from Hmm_emission_matrix import emission_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"E:\\\\msr_training.txt\") as f:\n",
    "    test = f.read()\n",
    "# t= test.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['“', '人们', '常', '说', '生活', '是', '一', '部', '教科书', '，', '而', '血', '与', '火', '的', '战争', '更', '是', '不可多得', '的', '教科书', '，', '她', '确实', '是', '名副其实', '的', '‘', '我', '的', '大学', '’', '。', '“', '心', '静', '渐', '知', '春', '似', '海', '，', '花', '深', '每', '觉', '影', '生', '香', '。', '“', '吃', '屎', '的', '东西', '，', '连', '一', '捆', '麦', '也', '铡', '不', '动', '呀', '？', '他', '“', '严格要求', '自己', '，', '从', '一个', '科举', '出身', '的', '进士', '成为', '一个', '伟大', '的', '民主主义', '者', '，', '进而', '成为', '一', '位', '杰出', '的', '党外', '共产主义', '战士', '，', '献身', '于', '崇高', '的', '共产主义', '事业']\n"
     ]
    }
   ],
   "source": [
    "wordlist = test.split()\n",
    "print(wordlist[:100]) # 原始分词语料集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 去掉一些为标注的词语\n",
    "# for index,i in enumerate(rawword_list):\n",
    "#     if \"/\" in i:\n",
    "#         continue\n",
    "#     else:\n",
    "#         rawword_list.pop(index)\n",
    "# print(rawword_list[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wordlist,partofspeechlist = map(list,zip(*(word.split(\"/\") for word in rawword_list)))\n",
    "# wordlist = [word.split(\"/\")[0] for word in rawword_list if word.split(\"/\")[0]!=''] # 通过/ 分割出词列表\n",
    "# print(wordlist[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getList(input_str):  #输入词语，输出状态\n",
    "    outpout_str = []\n",
    "    if len(input_str) == 1:\n",
    "        outpout_str.append('S')\n",
    "    elif len(input_str) == 2:\n",
    "        outpout_str = ['B','E']\n",
    "    else:\n",
    "        M_num = len(input_str) -2\n",
    "        M_list = ['M'] * M_num\n",
    "        outpout_str.append('B')\n",
    "        outpout_str.extend(M_list)  #把M_list中的'M'分别添加进去\n",
    "        outpout_str.append('E')\n",
    "    return outpout_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S', 'B', 'E', 'S', 'S', 'B', 'E', 'S', 'S', 'S', 'B', 'M', 'E', 'S', 'S', 'S', 'S', 'S', 'S', 'B', 'E', 'S', 'S', 'B', 'M', 'M', 'E', 'S', 'B', 'M', 'E', 'S', 'S', 'B', 'E', 'S', 'B', 'M', 'M', 'E', 'S', 'S', 'S', 'S', 'B', 'E', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'B', 'E', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'B', 'M', 'M', 'E', 'B', 'E', 'S', 'S', 'B', 'E', 'B', 'E', 'B', 'E', 'S', 'B']\n"
     ]
    }
   ],
   "source": [
    "wordbmes = map(getList,wordlist) # 对每个字进行BMES标注\n",
    "stateseq= [state for states in wordbmes for state in states] # 获取标注状态序列\n",
    "print(stateseq[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['“', '人', '们', '常', '说', '生', '活', '是', '一', '部', '教', '科', '书', '，', '而', '血', '与', '火', '的', '战', '争', '更', '是', '不', '可', '多', '得', '的', '教', '科', '书', '，', '她', '确', '实', '是', '名', '副', '其', '实', '的', '‘', '我', '的', '大', '学', '’', '。', '“', '心', '静', '渐', '知', '春', '似', '海', '，', '花', '深', '每', '觉', '影', '生', '香', '。', '“', '吃', '屎', '的', '东', '西', '，', '连', '一', '捆', '麦', '也', '铡', '不', '动', '呀', '？', '他', '“', '严', '格', '要', '求', '自', '己', '，', '从', '一', '个', '科', '举', '出', '身', '的', '进']\n"
     ]
    }
   ],
   "source": [
    "wordseq = [word for words in wordlist for word in words] # 获取词序列\n",
    "print(wordseq[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(len(wordseq)==len(stateseq)) # 查看两个序列长度是否相同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用鲍姆-韦尔奇算法\n",
    "states = np.unique(stateseq) \n",
    "n_states = len(states)\n",
    "observations = list(np.unique(wordseq))\n",
    "n_observations = len(observations)\n",
    "model = hmm.MultinomialHMM(n_components=n_states, n_iter=20, tol=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seen = list(map(lambda x:observations.index(x),wordseq))\n",
    "seen_array = np.array(seen).reshape(len(wordseq),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialHMM(n_components=4, n_iter=20,\n",
       "               random_state=RandomState(MT19937) at 0x19B8C9DCE40)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(seen_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4159],\n",
       "       [4149],\n",
       "       [1621],\n",
       "       [  72],\n",
       "       [3079],\n",
       "       [4469],\n",
       "       [4414],\n",
       "       [ 193],\n",
       "       [ 132],\n",
       "       [5113]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"谁说我不知道这件事？\"\n",
    "s_pre = np.array([[observations.index(i) for i in s]]).T\n",
    "s_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['E', 'E', 'B', 'B', 'M', 'E', 'M', 'E', 'B', 'M']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre = model.predict(s_pre)\n",
    "[states[i] for i in pre]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 不使用鲍姆-韦尔奇算法\n",
    "# def transition_matrix(sta_seq=None):\n",
    "#     \"\"\"\n",
    "#     计算状态转移矩阵\n",
    "#     seq : str or array_like\n",
    "#     states : numpy ndarray\n",
    "#     \"\"\"\n",
    "#     states = np.unique(sta_seq)\n",
    "#     seql = np.array(list(sta_seq))\n",
    "#     T = len(seql)\n",
    "#     K = len(states)\n",
    "#     matrix = np.zeros((K, K))\n",
    "\n",
    "#     for x, y in product(range(K), repeat=2):\n",
    "#         xid = np.argwhere(seql == states[x]).flatten()\n",
    "#         yid = xid + 1\n",
    "#         yid = yid[yid < T]\n",
    "#         s = np.count_nonzero(seql[yid] == states[y])\n",
    "#         matrix[x, y] = s\n",
    "\n",
    "#     matrix /= matrix.sum(axis=0)[:,None] # [:,None]确保 matrix除以的是纵轴上的和\n",
    "#     return matrix\n",
    "# %load_ext cython\n",
    "# %%cython\n",
    "# #!python\n",
    "# #cython: language_level=3\n",
    "\n",
    "# import numpy as np\n",
    "# import sys\n",
    "# import time\n",
    "# cimport numpy as np\n",
    "# cimport cython\n",
    "\n",
    "# @cython.boundscheck(False)\n",
    "# @cython.wraparound(False)\n",
    "# cpdef emission_matrix(obs_seq,sta_seq):\n",
    "#     \"\"\"\n",
    "#     计算发射矩阵\n",
    "#     \"\"\"\n",
    "#     cdef Py_ssize_t i,j\n",
    "#     cdef int k,n\n",
    "#     cdef np.ndarray os,ss,obs_space,states_space,o\n",
    "#     os = np.array(obs_seq) # 字序列\n",
    "#     ss = np.array(sta_seq) # 状态序列\n",
    "#     obs_space = np.unique(os) # 字集合\n",
    "#     states_space = np.unique(ss) # 状态集合\n",
    "#     k = states_space.size \n",
    "#     n = obs_space.size\n",
    "#     ef = np.zeros((k, n),dtype=np.intc) # 发射矩阵\n",
    "#     cdef int[:, :] ef_view = ef\n",
    "    \n",
    "#     # 此处可用cython加速\n",
    "#     for i in range(k): # ['B', 'E', 'M', 'S']\n",
    "#         print(f\"now state is {i}\")\n",
    "#         for j in range(n):# ['举', '乃', '久', '么', '义'...]\n",
    "#             # states_space:状态集合 ['B', 'E', 'M', 'S'] ,ss:状态序列 ，os:字序列\n",
    "#             # 状态i(B)在状态序列中的位置索引，从观测序列中取出同位置的字\n",
    "#             # i状态对应的所有字\n",
    "#             o = os[ss == states_space[i]] \n",
    "#             ef_view[i, j] = np.count_nonzero(o == obs_space[j]) # obs_space：字集合，状态i到j字的个数\n",
    "            \n",
    "#     ep = ef / ef.sum(axis=1)[:, None]\n",
    "#     return ep\n",
    "# def pi_matrix(sta_seq):\n",
    "#     \"\"\"\n",
    "#     初始状态矩阵\n",
    "#     \"\"\"\n",
    "#     state = np.unique(sta_seq)\n",
    "#     states = np.array(sta_seq)\n",
    "#     T = len(state)\n",
    "#     pi_ = np.zeros(T)\n",
    "#     for i in range(T):\n",
    "#         pi_[i] = np.sum(states==state[i])\n",
    "#     pi_ /= pi_.sum()\n",
    "#     return pi_\n",
    "\n",
    "# emissionmatrix = emission_matrix(wordseq,stateseq)\n",
    "# transitionmatrix= transition_matrix(stateseq) # 转移概率矩阵\n",
    "# emissionmatrix = emission_matrix(wordseq,stateseq) # 发射矩阵\n",
    "# pi = pi_matrix(stateseq) #初始概率分布"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": "100"
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
